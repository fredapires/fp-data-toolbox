{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **update_collection**\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Objectives**\n",
    "\n",
    "---\n",
    "\n",
    "Pipeline process for taking Helvault .csv files as inputs and storing them in a master \"collection_db.csv\" \n",
    "\n",
    "<br>\n",
    "\n",
    "- Input csv files from Helvault\n",
    "    - which format from helvault gives us the most info (we can filter out whatever isn't necessary)\n",
    "    - best format for output: Helvault Pro CSV\n",
    "    - import entire owned cards collection from Helvault \n",
    "    - How do we join in the deck / container that a given card is in?\n",
    "    - Can we export every individual container from Helvault at once to the process all .csv files at once?\n",
    "\n",
    "    - what is the best place to export the collection into for easy python ingestion?\n",
    "        1. Save to OneDrive (as in between staging) \n",
    "        2. copy from OneDrive to git folder for Helvault \n",
    "        - directly to git folder on phone?\n",
    "\n",
    "<br>\n",
    "\n",
    "- Output .csv file (collection_db.csv)\n",
    "    - export collection_db.csv to [text](https://)\n",
    "    - What is the best format?\n",
    "        - Primary keys\n",
    "            - scryfall_id\n",
    "            - name / front\n",
    "        - other useful data points\n",
    "            - back (for mdfcs)\n",
    "            - price\n",
    "            - set code (3 alpha numeric)\n",
    "            - color\n",
    "            - type\n",
    "            - proxy_ind (bool)\n",
    "                - use a placeholder status code from Helvault\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TO DOs**\n",
    "\n",
    "---\n",
    "\n",
    "- TODO [ ] `update_collection`: convert input/output processing and storage of collection_db to .parquet file format: 2022-09-25\n",
    "    - all other data formats can remain as .csvs for now.\n",
    "\n",
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports / Setup Environment**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_mgmt_fp import eda, fcal, notifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variable Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y-%m-%d %H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_helvault_owned_nm = 'helvaultPro.csv'\n",
    "input_helvault_owned_dir = 'C:\\\\git\\\\mtg-proj\\\\data\\\\input\\\\helvault_csv\\\\owned_cards_input\\\\'\n",
    "input_helvault_owned_path = input_helvault_owned_dir+input_helvault_owned_nm\n",
    "\n",
    "input_helvault_cntnr_dir = 'C:\\\\git\\\\mtg-proj\\\\data\\\\input\\\\helvault_csv\\\\'\n",
    "input_helvault_cntnr_path = input_helvault_cntnr_dir+''\n",
    "\n",
    "archive_git_nm = 'collection_db_arch_'+dt_string+'.csv'\n",
    "archive_git_dir = 'C:\\\\git\\\\mtg-proj\\\\data\\\\output\\\\collection_db\\\\.archive'\n",
    "archive_git_path = archive_git_dir+'\\\\'+archive_git_nm\n",
    "\n",
    "output_csv_nm = 'collection_db.csv'\n",
    "output_csv_dir = 'C:\\\\git\\\\mtg-proj\\\\data\\\\output\\\\collection_db\\\\'\n",
    "output_csv_path = output_csv_dir+output_csv_nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Ingestion/Preprocessing**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_owned_df = pd.read_csv(input_helvault_owned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index_col\n",
    "input_owned_df['index_col'] = input_owned_df.index\n",
    "\n",
    "input_owned_df = input_owned_df.rename(columns={\"estimated_price\": \"estimated_price_upd\"}, errors=\"raise\")\n",
    "\n",
    "# re-order colms\n",
    "input_owned_df = input_owned_df.reindex([\n",
    "    'scryfall_id',\n",
    "    'estimated_price_upd'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all csv files at once and glue them together\n",
    "import glob\n",
    "\n",
    "directoryPath = input_helvault_cntnr_path\n",
    "\n",
    "glued_data_df = pd.DataFrame()\n",
    "for file_name in glob.glob(directoryPath+'*.csv'):\n",
    "    df = pd.read_csv(file_name, low_memory=False)\n",
    "\n",
    "    cntnr_txt_var = file_name.rsplit('\\\\', 1)[-1] or file_name\n",
    "    cntnr_txt_var = cntnr_txt_var.split('.')[0] or cntnr_txt_var\n",
    "\n",
    "    cntnr_type_var = cntnr_txt_var.split('-')[0] or cntnr_txt_var\n",
    "    cntnr_name_var = cntnr_txt_var.split('-')[1] or cntnr_txt_var\n",
    "\n",
    "    df['cntnr_type'] = cntnr_type_var\n",
    "    df['cntnr_name'] = cntnr_name_var\n",
    "    glued_data_df = pd.concat([glued_data_df,df],axis=0)\n",
    "\n",
    "glued_data_df=glued_data_df.sort_values(by=['set_code','collector_number'])\n",
    "\n",
    "glued_data_df=glued_data_df.reset_index()\n",
    "glued_data_df['index_col'] = glued_data_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_db_df_stg = glued_data_df\n",
    "collection_db_df_stg = collection_db_df_stg.rename(columns={\"estimated_price\": \"price_est_usd\"}, errors=\"raise\")\n",
    "collection_db_df_stg = collection_db_df_stg.rename(columns={\"quantity\": \"count_owned\"}, errors=\"raise\")\n",
    "\n",
    "#column reordering for readability\n",
    "collection_db_df_stg = collection_db_df_stg.reindex([\n",
    "    'index_col',\n",
    "    'scryfall_id',\n",
    "    'oracle_id',\n",
    "    'name',\n",
    "    'extras',\n",
    "    'cntnr_type',\n",
    "    'cntnr_name',\n",
    "    'set_code',\n",
    "    'set_name',\n",
    "    'collector_number',\n",
    "    'rarity',\n",
    "    'language',\n",
    "    'count_owned',\n",
    "    'price_est_usd'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scrython Data Ingestion**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting scryfall api search for prices; might take a few minutes\n",
      "done searching scryfall api; no errors\n"
     ]
    }
   ],
   "source": [
    "# [x] add data pull from scryfall\n",
    "import nest_asyncio\n",
    "import scrython\n",
    "\n",
    "scryfall_id_list = collection_db_df_stg['scryfall_id'].tolist()\n",
    "\n",
    "price_list = []\n",
    "index = len(scryfall_id_list)\n",
    "\n",
    "# ====================================\n",
    "\n",
    "nest_asyncio.apply()\n",
    "i = 0\n",
    "\n",
    "print('starting scryfall api search for prices; might take a few minutes')\n",
    "for sf_id in scryfall_id_list:\n",
    "    card = scrython.cards.Id(id=sf_id)\n",
    "    card_price_str = card.prices('usd')\n",
    "    price_list.append(card_price_str)\n",
    "    i = i + 1\n",
    "    progress_stat = str(round((i / index),2)) + ' / 1.00'\n",
    "    print(progress_stat, end='\\r')\n",
    "    # print(card_price_str, end=\"            \")\n",
    "print('done searching scryfall api; no errors')\n",
    "\n",
    "collection_db_df_stg['price_est_usd'] = price_list\n",
    "\n",
    "# ===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleaning / Transform**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# transform set_code to be all upper case \n",
    "collection_db_df_stg['set_code'] = collection_db_df_stg['set_code'].str.upper()\n",
    "\n",
    "# add front and back fields for MPC input\n",
    "# new data frame with split value columns\n",
    "split_df = collection_db_df_stg[\"name\"].str.split(\"//\", n = 1, expand = True)\n",
    "# making separate first name column from new data frame\n",
    "collection_db_df_stg[\"front\"]= split_df[0]\n",
    "# making separate last name column from new data frame\n",
    "collection_db_df_stg[\"back\"]= split_df[1]\n",
    "\n",
    "# cleaning count owned\n",
    "collection_db_df_stg['count_owned']=collection_db_df_stg['count_owned'].fillna(0)\n",
    "collection_db_df_stg['count_owned']=collection_db_df_stg['count_owned'].astype(int)\n",
    "# cleaning price\n",
    "collection_db_df_stg['price_est_usd'] = collection_db_df_stg['price_est_usd'].astype(float)\n",
    "\n",
    "# lower limit of $0 on estimated_price field\n",
    "collection_db_df_stg['price_est_usd'] = collection_db_df_stg['price_est_usd'].clip(0,1000000)\n",
    "\n",
    "\n",
    "collection_db_df_stg['extras']=collection_db_df_stg['extras'].astype(str)\n",
    "# ====================================\n",
    "# [x] converting extras to 'alteredArt'\n",
    "collection_db_df_stg['extras'] = np.where(\n",
    "    collection_db_df_stg['cntnr_name'].str.find('Proxy') != -1,\n",
    "    'alteredArt',\n",
    "    collection_db_df_stg['extras']\n",
    ");\n",
    "\n",
    "collection_db_df_stg['extras'] = collection_db_df_stg['extras'].apply(\n",
    "    lambda x: x.replace('misprint', 'alteredArt')\n",
    ");\n",
    "\n",
    "# collection_db_df_stg['extras'] = collection_db_df_stg['extras_s2']\n",
    "# collection_db_df_stg['extras'] = collection_db_df_stg['extras_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final column reordering\n",
    "collection_db_df_stg = collection_db_df_stg.reindex([\n",
    "    'index_col',\n",
    "    'oracle_id',\n",
    "    'scryfall_id',\n",
    "    'name',\n",
    "    'front',\n",
    "    'back',\n",
    "    'extras',\n",
    "    'cntnr_type',\n",
    "    'cntnr_name',\n",
    "    'set_code',\n",
    "    'set_name',\n",
    "    'collector_number',\n",
    "    'rarity',\n",
    "    'language',\n",
    "    'count_owned',\n",
    "    'price_est_usd'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.copi_df(collection_db_df_stg)\n",
    "# collection_db_df_stg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outputs**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_db_df_stg.to_csv(output_csv_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save to Archive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_db_df_stg.to_csv(archive_git_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "bf2256466664d08ad5829690b78a52ff85021f5c7c81ebd85ac567841dd5c95f"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
