{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **scrython_bulk_data_etl**\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Objectives**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TO DOs**\n",
    "\n",
    "---\n",
    "\n",
    "- [x] 2022-10-03 23:37:15: setup proc `[scrython_bulk_data_etl]`: 2022-10-01\n",
    "    \n",
    "- [x] 2022-10-03 23:37:21: setup gitignore to ignore the json data dump and our saved parquet file\n",
    "\n",
    "- TODO [ ] finish final docs on this proc: 2022-10-03\n",
    "\n",
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports / Setup Environment**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fp_data_toolbox import eda, notifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Variable Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "ts_string = now.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "dt_string = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "###=============================================\n",
    "### variables for feather file pathing\n",
    "\n",
    "resources_dir = 'C:\\\\git\\\\mtg-proj\\\\mtg-etl\\\\resources\\\\scryfall_api_data'\n",
    "default_cards_feather_name='default_cards-'+dt_string+'.feather'\n",
    "oracle_cards_feather_name='oracle_cards-'+dt_string+'.feather'\n",
    "\n",
    "default_cards_feather_path = resources_dir+'\\\\'+default_cards_feather_name\n",
    "oracle_cards_feather_path = resources_dir+'\\\\'+oracle_cards_feather_name\n",
    "\n",
    "###=============================================\n",
    "### variables for JSON file pathing\n",
    "\n",
    "default_cards_json_name='default_cards-'+dt_string+'.json'\n",
    "oracle_cards_json_name='oracle_cards-'+dt_string+'.json'\n",
    "\n",
    "default_cards_json_wildcard='default_cards*'\n",
    "oracle_cards_json_wildcard='oracle_cards*'\n",
    "\n",
    "default_cards_json_path = resources_dir+'\\\\'+default_cards_json_name\n",
    "oracle_cards_json_path = resources_dir+'\\\\'+oracle_cards_json_name\n",
    "\n",
    "default_cards_json_path_wc = resources_dir+'\\\\'+default_cards_json_wildcard\n",
    "oracle_cards_json_path_wc = resources_dir+'\\\\'+oracle_cards_json_wildcard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Flow Control**\n",
    "\n",
    "---\n",
    "\n",
    "- [ ] check whether scryfall mass data file exists; if no, start create script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_cards-2022-10-03\n",
      "default_cards-2022-10-03\n",
      "oracle_cards-2022-10-03\n",
      "oracle_cards-2022-10-03\n"
     ]
    }
   ],
   "source": [
    "bool_default_cards_json_exists = False\n",
    "bool_oracle_cards_json_exists = False\n",
    "import os\n",
    "for filename in os.scandir(resources_dir):\n",
    "    if filename.is_file():\n",
    "        filename_str=filename.path.rsplit('\\\\', 1)[1] or filename.path \n",
    "        filename_str=filename_str.rsplit('.', 1)[0] or filename_str # find the filename \n",
    "        print(filename_str)\n",
    "        if filename_str.startswith('default_cards') and filename.path.endswith('.json'):\n",
    "            file_dt_str=filename_str.rsplit('-', 3)[1]+'-'+filename_str.rsplit('-', 2)[1]+'-'+filename_str.rsplit('-', 1)[1]\n",
    "            if file_dt_str == dt_string:\n",
    "            # TODO [ ] add logic for matching on date as well\n",
    "                bool_default_cards_json_exists = True\n",
    "                continue\n",
    "        if filename_str.startswith('oracle_cards') and filename.path.endswith('.json'):\n",
    "            file_dt_str=filename_str.rsplit('-', 3)[1]+'-'+filename_str.rsplit('-', 2)[1]+'-'+filename_str.rsplit('-', 1)[1]\n",
    "            if file_dt_str == dt_string:\n",
    "            # TODO [ ] add logic for matching on date as well\n",
    "                bool_oracle_cards_json_exists = True\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scrython Data Ingestion**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] download api data dump as json\n",
    "- [x] convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for downloading json files from url\n",
    "def download_json_from_https(scryfall_bulk_data_name,path_out):\n",
    "    import requests\n",
    "    import os\n",
    "    import nest_asyncio\n",
    "    \n",
    "    nest_asyncio.apply()\n",
    "    i = 0\n",
    "    import scrython\n",
    "\n",
    "    # setup method for pulling metadata from scrython\n",
    "    data_info = scrython.bulk_data.BulkData()\n",
    "\n",
    "    # pull scryfall metadata into string\n",
    "    scryfall_metadata_str = data_info.data()\n",
    "\n",
    "    # converting str to json and writing to .json file\n",
    "    import json\n",
    "    json_object = json.dumps(scryfall_metadata_str, indent=4)\n",
    "    with open(\"scryfall_metadata.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "    # reading .json file as df\n",
    "    df_scryfall_metadata = pd.read_json(\"scryfall_metadata.json\").set_index('name')    \n",
    "\n",
    "    download_uri = df_scryfall_metadata.loc[scryfall_bulk_data_name, 'download_uri']\n",
    "\n",
    "    print(scryfall_bulk_data_name)\n",
    "    #download url\n",
    "    r = requests.get(download_uri, allow_redirects=True)\n",
    "    # writing to json\n",
    "    open(path_out, 'wb').write(r.content)\n",
    "    # reading json as df\n",
    "    df = pd.read_json(path_out)\n",
    "    # deleting temp json file\n",
    "    # os.remove(temp_filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_cards already cached; won\"t pull again\n",
      "oracle_cards bulk_data already cached; won\"t pull again\n"
     ]
    }
   ],
   "source": [
    "## downloading bulk data from scryfall (if not already cached)\n",
    "default_cards_bulk_data_name = 'Default Cards'\n",
    "oracle_cards_bulk_data_name = 'Oracle Cards'\n",
    "\n",
    "import glob\n",
    "\n",
    "###=============================================\n",
    "if bool_default_cards_json_exists == False:\n",
    "    \n",
    "    # get a recursive list of file paths that matches pattern including sub directories\n",
    "    fileList = glob.glob('C:/git/mtg-proj/mtg-etl/resources/scryfall_api_data/default_cards*.json', recursive=True)\n",
    "    # Iterate over the list of filepaths & remove each file.\n",
    "    for filePath in fileList:\n",
    "        try:\n",
    "            os.remove(filePath)\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")\n",
    "\n",
    "    # os.remove(default_cards_json_path_wc)\n",
    "    print('starting default_cards bulk_data pull; might take a few seconds')\n",
    "    df_default_cards = download_json_from_https(default_cards_bulk_data_name,default_cards_json_path)\n",
    "    print('done pulling default_cards bulk_data ; no errors')\n",
    "else:\n",
    "    print('default_cards already cached; won\"t pull again')\n",
    "    df_default_cards = pd.read_json(default_cards_json_path)\n",
    "###=============================================\n",
    "\n",
    "if bool_oracle_cards_json_exists == False:\n",
    "\n",
    "    # get a recursive list of file paths that matches pattern including sub directories\n",
    "    fileList = glob.glob('C:/git/mtg-proj/mtg-etl/resources/scryfall_api_data/oracle_cards*.json', recursive=True)\n",
    "    # Iterate over the list of filepaths & remove each file.\n",
    "    for filePath in fileList:\n",
    "        try:\n",
    "            os.remove(filePath)\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")\n",
    "\n",
    "    # os.remove(oracle_cards_json_path_wc)\n",
    "    print('starting oracle_cards bulk_data pull; might take a few seconds')\n",
    "    df_oracle_cards = download_json_from_https(oracle_cards_bulk_data_name,oracle_cards_json_path)\n",
    "    print('done pulling oracle_cards bulk_data ; no errors')\n",
    "else:\n",
    "    print('oracle_cards bulk_data already cached; won\"t pull again')\n",
    "    df_oracle_cards = pd.read_json(oracle_cards_json_path)\n",
    "###=============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleaning / Transform**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] set proper indexes\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- [ ] split `prices` field into multiple price fields\n",
    "\n",
    "- [ ] optimize df for parquet storage\n",
    "    - [ ] cast best datatypes\n",
    "\n",
    "- [ ] add any features we need to create ourselvess\n",
    "\n",
    "<br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO [ ] summarize all cleaning operations into one scryfall_bulk_data_clean function: 2022-10-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scryfall_bulk_data_clean(df_input):\n",
    "    df=df_input\n",
    "    df=df.rename(columns={\n",
    "        # DONE [x] clean up names (renaming): 2022-10-02\n",
    "        \"uri\": \"api_uri\",\n",
    "        \"lang\": \"language\",\n",
    "        # add more column name changes here\n",
    "        \"released_at\": \"released_date\"\n",
    "    }, errors=\"raise\")\n",
    "    \n",
    "    \n",
    "    ###=============================================\n",
    "    ### DONE [x]  fields to unpack;noted_on:2022-10-02\n",
    "        ### [x]  'prices'\n",
    "    ## unpack fields into new data frame\n",
    "    df_prices=pd.DataFrame()\n",
    "    df_prices=pd.DataFrame(df['prices'].to_list(), columns=[\n",
    "        'usd', \n",
    "        'usd_foil', \n",
    "        'usd_etched', \n",
    "        # 'eur', \n",
    "        # 'eur_foil', \n",
    "        'tix'\n",
    "        ])\n",
    "    df_prices['id']=df['id']\n",
    "    ### merge df_prices back into main df\n",
    "    df=df.merge(df_prices, on='id', how='left')\n",
    "    # del df_prices\n",
    "    \n",
    "    ###=============================================\n",
    "    ### [x]  unpack  'related_uris'\n",
    "    df_uris=pd.DataFrame()\n",
    "    df_uris=pd.DataFrame(df['related_uris'].to_list(), columns=[\n",
    "        'gatherer', \n",
    "        # 'tcgplayer_infinite_articles', \n",
    "        # 'tcgplayer_infinite_decks', \n",
    "        'edhrec'\n",
    "        ])\n",
    "    df_uris['id']=df['id']\n",
    "    ### rename columns\n",
    "    df_uris=df_uris.rename(columns={\n",
    "        \"gatherer\": \"gatherer_uri\",\n",
    "        # \"tcgplayer_infinite_articles\": \"tcgplayer_infinite_articles_uri\", \n",
    "        # \"tcgplayer_infinite_decks\": \"tcgplayer_infinite_decks_uri\", \n",
    "        \"edhrec\": \"edhrec_uri\"\n",
    "    }, errors=\"raise\")\n",
    "    ### merge df_uris back into main df\n",
    "    df=df.merge(df_uris, on='id', how='left')\n",
    "    # del df_uris\n",
    "    \n",
    "    ###=============================================\n",
    "    ### SOMEDAY unpack 'legalities'\n",
    "    \n",
    "    ### SOMEDAY unpack 'games'\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###=============================================\n",
    "    # - [x] eliminate completely unnecessary fields\n",
    "        # - `related_uri`\n",
    "    df=df.drop(columns=[\n",
    "        # add more fields to drop here\n",
    "        'object',\n",
    "        'highres_image',\n",
    "        'color_indicator',\n",
    "        'hand_modifier',\n",
    "        'life_modifier',\n",
    "        'loyalty',\n",
    "        'image_status',\n",
    "        'image_uris',\n",
    "        'prints_search_uri',\n",
    "        'artist_ids',\n",
    "        'illustration_id',\n",
    "        'tcgplayer_etched_id',\n",
    "        'preview',\n",
    "        'all_parts',\n",
    "        'promo_types',\n",
    "        'content_warning',\n",
    "        'story_spotlight',\n",
    "        'textless',\n",
    "        'attraction_lights',\n",
    "    \n",
    "    ### drop unpacked columns from main df\n",
    "        'related_uris',\n",
    "        'legalities',\n",
    "        'games',\n",
    "        'prices'\n",
    "    ])\n",
    "\n",
    "    ###=============================================\n",
    "    ### [ ]  cast the correct data types here\n",
    "        ### 'df.astype'\n",
    "        ### [x] prices as downcast float\n",
    "        ### [ ] categorical fields as category\n",
    "        ### [x] boolean fields as boolean\n",
    "    \n",
    "    ## float fields\n",
    "    df['usd'] = pd.to_numeric(df['usd'], downcast='float')\n",
    "    df['usd_foil'] = pd.to_numeric(df['usd_foil'], downcast='float')\n",
    "    df['usd_etched'] = pd.to_numeric(df['usd_etched'], downcast='float')\n",
    "    df['tix'] = pd.to_numeric(df['tix'], downcast='float')\n",
    "    df['cmc'] = pd.to_numeric(df['cmc'], downcast='float')\n",
    "    # df['power'] = pd.to_numeric(df['power'], downcast='float')        # not actually a float field (strings exist)\n",
    "    # df['tougness'] = pd.to_numeric(df['tougness'], downcast='float')  # not actually a float field (strings exist)\n",
    "    \n",
    "    ## integer fields\n",
    "    df['penny_rank'] = pd.to_numeric(df['penny_rank'], downcast='integer')\n",
    "    df['edhrec_rank'] = pd.to_numeric(df['edhrec_rank'], downcast='integer')\n",
    "    df['cardmarket_id'] = pd.to_numeric(df['cardmarket_id'], downcast='integer')\n",
    "    df['tcgplayer_id'] = pd.to_numeric(df['tcgplayer_id'], downcast='integer')\n",
    "    df['arena_id'] = pd.to_numeric(df['arena_id'], downcast='integer')\n",
    "    \n",
    "    # ## category fields\n",
    "    df['set_type'] =            df['set_type'].astype('category')\n",
    "    df['language'] =            df['language'].astype('category')\n",
    "    df['security_stamp'] =      df['security_stamp'].astype('category')\n",
    "    df['rarity'] =              df['rarity'].astype('category')\n",
    "    # df['frame_effects'] =       df['frame_effects'].astype('category')    # actually a list data type, not a string\n",
    "    df['layout'] =              df['layout'].astype('category')\n",
    "    # df['finishes'] =            df['finishes'].astype('category')         # actually a list data type, not a string\n",
    "    df['border_color'] =        df['border_color'].astype('category')\n",
    "    df['frame'] =               df['frame'].astype('category')\n",
    "    df['watermark'] =           df['watermark'].astype('category')\n",
    "    \n",
    "    # ## boolean fields    \n",
    "    df['reserved'] =            df['reserved'].astype('boolean')\n",
    "    df['foil'] =                df['foil'].astype('boolean')\n",
    "    df['nonfoil'] =             df['nonfoil'].astype('boolean')\n",
    "    df['oversized'] =           df['oversized'].astype('boolean')\n",
    "    df['promo'] =               df['promo'].astype('boolean')\n",
    "    df['reprint'] =             df['reprint'].astype('boolean')\n",
    "    df['variation'] =           df['variation'].astype('boolean')\n",
    "    df['digital'] =             df['digital'].astype('boolean')\n",
    "    df['full_art'] =            df['full_art'].astype('boolean')\n",
    "    df['booster'] =             df['booster'].astype('boolean')\n",
    "    \n",
    "    # ## object fields\n",
    "    df['colors'] =              df['colors'].astype('object')\n",
    "    df['color_identity'] =      df['color_identity'].astype('object')\n",
    "    df['keywords'] =            df['keywords'].astype('object')\n",
    "    df['produced_mana'] =       df['produced_mana'].astype('object')\n",
    "    df['card_faces'] =          df['card_faces'].astype('object')\n",
    "    df['frame_effects'] =       df['frame_effects'].astype('object')\n",
    "    df['finishes'] =            df['finishes'].astype('object')\n",
    "    df['multiverse_ids'] =      df['multiverse_ids'].astype('object')\n",
    "    \n",
    "    ###=============================================\n",
    "    ### transform 'set' field to uppercase    \n",
    "    df['set']=df['set'].str.upper()\n",
    "\n",
    "    ### [x] reorder columns \n",
    "    df=df[[\n",
    "        'id',\n",
    "        'name',\n",
    "        \n",
    "        ###=============================================\n",
    "        ### price data\n",
    "        'usd',\n",
    "        'usd_foil',\n",
    "        'usd_etched',\n",
    "        'tix',\n",
    "        \n",
    "        ###=============================================\n",
    "        ### on-card / strategic data\n",
    "        'cmc',\n",
    "        'mana_cost',\n",
    "        'colors',\n",
    "        'color_identity',\n",
    "        'power',\n",
    "        'toughness',\n",
    "        'type_line',\n",
    "        'keywords',\n",
    "        'produced_mana',\n",
    "        'oracle_text',\n",
    "        \n",
    "        ###=============================================\n",
    "        ### rank data\n",
    "        'penny_rank',\n",
    "        'edhrec_rank',\n",
    "        \n",
    "        ###=============================================\n",
    "        ### collector fields\n",
    "        'collector_number',\n",
    "        'set',\n",
    "        'set_name',\n",
    "        'set_type',\n",
    "        'released_date',\n",
    "        'language',\n",
    "        'security_stamp',\n",
    "        'rarity',\n",
    "        'card_faces',\n",
    "        'frame_effects',\n",
    "        'layout',\n",
    "        'watermark',\n",
    "        'finishes',\n",
    "        'artist',\n",
    "        'border_color',\n",
    "        'frame',\n",
    "        'flavor_text',        \n",
    "        \n",
    "        ### boolean collector fields\n",
    "        'reserved',\n",
    "        'foil',\n",
    "        'nonfoil',\n",
    "        'oversized',\n",
    "        'promo',\n",
    "        'reprint',\n",
    "        'variation',\n",
    "        'digital',\n",
    "        'full_art',\n",
    "        'booster',\n",
    "        \n",
    "        ###=============================================\n",
    "        ### ids\n",
    "        'oracle_id',\n",
    "        'set_id',\n",
    "        'mtgo_id',\n",
    "        'mtgo_foil_id',\n",
    "        'cardmarket_id',\n",
    "        'tcgplayer_id',\n",
    "        \n",
    "        'arena_id',\n",
    "        'card_back_id',\n",
    "        'multiverse_ids',\n",
    "        \n",
    "        ###=============================================\n",
    "        ### uris\n",
    "        'api_uri',\n",
    "        'set_uri',\n",
    "        'set_search_uri',\n",
    "        'scryfall_uri',\n",
    "        'scryfall_set_uri',\n",
    "        'rulings_uri',        \n",
    "        'gatherer_uri',\n",
    "        'edhrec_uri'\n",
    "    ]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default_cards=scryfall_bulk_data_clean(df_default_cards)\n",
    "df_oracle_cards=scryfall_bulk_data_clean(df_oracle_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [x] clean up `id` dimensionality for `df_oracle_cards`\n",
    "#     - needs to be completely distinct on `id`\n",
    "# - [x] ways of eliminating `id` duplicates\n",
    "#         - group by `id` for min `price_usd` into new df\n",
    "\n",
    "df_default_cards_stg = pd.DataFrame()\n",
    "df_default_cards_stg['id']=df_default_cards['id']\n",
    "df_default_cards_stg['usd']=df_default_cards['usd']\n",
    "\n",
    "df_default_cards_id=df_default_cards_stg.groupby(by='id').min()\n",
    "\n",
    "df_default_cards = pd.merge(df_default_cards, df_default_cards_id, on='id', how='inner')\n",
    "\n",
    "df_default_cards=df_default_cards.rename(columns={\n",
    "        \"usd_x\": \"usd\"\n",
    "    }, errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [x] clean up `name` dimensionality for `df_default_cards`\n",
    "#   - needs to be completely distinct on `name`\n",
    "# - [x] eliminating `name` duplicates\n",
    "#     - group by `name` for max `id` into new df\n",
    "\n",
    "df_oracle_cards_stg = pd.DataFrame()\n",
    "df_oracle_cards_stg['name']=df_oracle_cards['name']\n",
    "df_oracle_cards_stg['id']=df_oracle_cards['id']\n",
    "\n",
    "df_oracle_cards_id=df_oracle_cards_stg.groupby(by='name').max()\n",
    "\n",
    "df_oracle_cards = pd.merge(df_oracle_cards, df_oracle_cards_id, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [x] sort and reindex\n",
    "df_default_cards=df_default_cards.sort_values(by=['name','id'])\n",
    "df_default_cards=df_default_cards.reset_index(drop=True)\n",
    "\n",
    "df_oracle_cards=df_oracle_cards.sort_values(by=['name','id'])\n",
    "df_oracle_cards=df_oracle_cards.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set index fields\n",
    "# df_default_cards = df_default_cards.set_index('name')\n",
    "# df_default_cards['name'] = df_default_cards.index\n",
    "\n",
    "# df_oracle_cards = df_oracle_cards.set_index('id')\n",
    "# df_oracle_cards['id'] = df_oracle_cards.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df=df_oracle_cards\n",
    "# df=df_default_cards\n",
    "# eda.copi_df(df)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outputs**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO [ ] save as feather file in local storage\n",
    "    - [ ] decide on location of feather output\n",
    "        - can this be integrated within python modules that can be imported by other procs?\n",
    "    - [ ] create var for feather output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feather\n",
    "\n",
    "### TODO [ ] logic for skipping scrython_bulk_data_etl processing ;noted_on:2022-10-03\n",
    "    ### when feather file all ready present and date ts matches\n",
    "df_default_cards.to_feather(default_cards_feather_path)\n",
    "df_oracle_cards.to_feather(oracle_cards_feather_path)\n",
    "\n",
    "# df_oracle_cards.to_feather()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save to Archive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if we'll need this\n",
    "# fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unit Test**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default_cards_test = pd.read_feather(default_cards_feather_path)\n",
    "df_oracle_cards_test = pd.read_feather(oracle_cards_feather_path)\n",
    "# fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73388 entries, 0 to 73387\n",
      "Data columns (total 63 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   id                73388 non-null  object        \n",
      " 1   name              73388 non-null  object        \n",
      " 2   usd               55034 non-null  float32       \n",
      " 3   usd_foil          36264 non-null  float32       \n",
      " 4   usd_etched        729 non-null    float32       \n",
      " 5   tix               35738 non-null  float32       \n",
      " 6   cmc               73383 non-null  float32       \n",
      " 7   mana_cost         71423 non-null  object        \n",
      " 8   colors            71423 non-null  object        \n",
      " 9   color_identity    73388 non-null  object        \n",
      " 10  power             34333 non-null  object        \n",
      " 11  toughness         34333 non-null  object        \n",
      " 12  type_line         73383 non-null  object        \n",
      " 13  keywords          73388 non-null  object        \n",
      " 14  produced_mana     10696 non-null  object        \n",
      " 15  oracle_text       71001 non-null  object        \n",
      " 16  penny_rank        40386 non-null  float64       \n",
      " 17  edhrec_rank       63711 non-null  float64       \n",
      " 18  collector_number  73388 non-null  object        \n",
      " 19  set               73388 non-null  object        \n",
      " 20  set_name          73388 non-null  object        \n",
      " 21  set_type          73388 non-null  category      \n",
      " 22  released_date     73388 non-null  datetime64[ns]\n",
      " 23  language          73388 non-null  category      \n",
      " 24  security_stamp    18917 non-null  category      \n",
      " 25  rarity            73388 non-null  category      \n",
      " 26  card_faces        2387 non-null   object        \n",
      " 27  frame_effects     7041 non-null   object        \n",
      " 28  layout            73388 non-null  category      \n",
      " 29  watermark         5131 non-null   category      \n",
      " 30  finishes          73388 non-null  object        \n",
      " 31  artist            73388 non-null  object        \n",
      " 32  border_color      73388 non-null  category      \n",
      " 33  frame             73388 non-null  category      \n",
      " 34  flavor_text       35701 non-null  object        \n",
      " 35  reserved          73388 non-null  boolean       \n",
      " 36  foil              73388 non-null  boolean       \n",
      " 37  nonfoil           73388 non-null  boolean       \n",
      " 38  oversized         73388 non-null  boolean       \n",
      " 39  promo             73388 non-null  boolean       \n",
      " 40  reprint           73388 non-null  boolean       \n",
      " 41  variation         73388 non-null  boolean       \n",
      " 42  digital           73388 non-null  boolean       \n",
      " 43  full_art          73388 non-null  boolean       \n",
      " 44  booster           73388 non-null  boolean       \n",
      " 45  oracle_id         73383 non-null  object        \n",
      " 46  set_id            73388 non-null  object        \n",
      " 47  mtgo_id           37765 non-null  float64       \n",
      " 48  mtgo_foil_id      24259 non-null  float64       \n",
      " 49  cardmarket_id     60524 non-null  float64       \n",
      " 50  tcgplayer_id      62548 non-null  float64       \n",
      " 51  arena_id          9410 non-null   float64       \n",
      " 52  card_back_id      71423 non-null  object        \n",
      " 53  multiverse_ids    73388 non-null  object        \n",
      " 54  api_uri           73388 non-null  object        \n",
      " 55  set_uri           73388 non-null  object        \n",
      " 56  set_search_uri    73388 non-null  object        \n",
      " 57  scryfall_uri      73388 non-null  object        \n",
      " 58  scryfall_set_uri  73388 non-null  object        \n",
      " 59  rulings_uri       73388 non-null  object        \n",
      " 60  gatherer_uri      49125 non-null  object        \n",
      " 61  edhrec_uri        73359 non-null  object        \n",
      " 62  usd_y             55034 non-null  float32       \n",
      "dtypes: boolean(10), category(8), datetime64[ns](1), float32(6), float64(7), object(31)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df_default_cards\n",
    "# df = df_oracle_cards\n",
    "eda.copi_df(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleanup**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up intermediate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fill in \n",
    "# os.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_default_cards\n",
    "df = df_oracle_cards\n",
    "eda.copi_df(df)\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "bf2256466664d08ad5829690b78a52ff85021f5c7c81ebd85ac567841dd5c95f"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
